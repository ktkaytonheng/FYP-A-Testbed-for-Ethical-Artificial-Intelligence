# FYP - A Testbed for Ethical Artificial Intelligence
In this project, we aim to subject a reinforcement learning (RL) agent and human participants to various ethical dilemmas in a war game built in unity and using Unity Machine Learning (ML) Agents. The game environment is built in unity 3D game engine and will be in a context of a battle, where an RL agent needs to make decisions based on collateral damage of noncombatants. The agent controls a turret, which needs to eliminate enemy units while preventing damage to noncombatants such as children, or neutral building.  This study is similar to the moral machine project, where human participants judge 13 moral dilemmas involving an autonomous vehicle. In addition, we will design various dilemmas where friendly units or noncombatants will be harmed alongside enemy counterparts and observe how the RL agent/human participant responds to the scenario. The goal of this project is to build an ethical AI agent that minimizes collateral damage while achieving its objective of destroying enemy targets.
